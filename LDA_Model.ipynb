{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8EgmCJTADHmKhKlrFuqtH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanucode/Deep-Learning-Practice/blob/main/LDA_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZfMkXzJlM2u",
        "outputId": "4df0801a-e778-485f-8e07-325a721e9d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel (\"games.xlsx\")\n",
        "print (df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaqTRYkdlxFl",
        "outputId": "363c3220-8207-45d3-8f97-25a2a303c958"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain             app                             review_id  \\\n",
            "0      productivity        things-3  c9274c0a-a120-4e09-816b-7a8ba3a16634   \n",
            "1      productivity      notability  e633e20a-07c1-4a5e-80b1-b104b6cf6a61   \n",
            "2      productivity  microsoft-word  506230e3-cc98-4233-be40-89e52d53990c   \n",
            "3      productivity        things-3  69d44a5e-218f-4f55-8a99-6cca55d43ca1   \n",
            "4      productivity      notability  3d0b634c-d402-47e8-ba7d-bf6209fed826   \n",
            "...             ...             ...                                   ...   \n",
            "11316         games       among-us-  70d02d85-60b0-4c94-a43d-0307f089e36e   \n",
            "11317         games  subway-surfers  5431fed8-7c83-4ea1-bc4e-c2282c6f1bbd   \n",
            "11318         games        monopoly  5880f046-3a22-4dd9-8b01-ab6dea2bd4f6   \n",
            "11319         games       among-us-  8765dd75-e764-4d94-a2ea-f23c8894908d   \n",
            "11320         games        heads-up  27d1206e-e930-4944-b4cb-5d61a2e58d91   \n",
            "\n",
            "                                sentence_id  \\\n",
            "0      00808934-e8b9-42fa-b37f-cfeac234bbdd   \n",
            "1      00a8d4a4-9c8e-4d1c-9085-ffd1f62ae039   \n",
            "2      011cd77b-ebbd-4589-af12-9792975b02b9   \n",
            "3      014a7d01-f6c0-408a-897b-f6b36cdd8543   \n",
            "4      01539a8d-ebde-4cfe-9b5b-3fa10f49fa3e   \n",
            "...                                     ...   \n",
            "11316  166c4b99-efe7-4d4c-8afa-3e09f4937796   \n",
            "11317  42d9aa0e-7183-4148-996f-8e90e7852abf   \n",
            "11318  2a82db36-9f4a-49f4-8d70-551a900222a9   \n",
            "11319  92ab173f-cad1-4fa9-bcc3-eb1a2dfed83b   \n",
            "11320  13501da9-ddbe-4c92-9da9-0190df2ea423   \n",
            "\n",
            "                                   title  \\\n",
            "0      Difficult to update from Things 2   \n",
            "1                              Great app   \n",
            "2                Same word. Same problem   \n",
            "3        Incredible Planner for Students   \n",
            "4                  Recording and syncing   \n",
            "...                                  ...   \n",
            "11316        My experience with Among Us   \n",
            "11317          ARE YOU KIDDING ME!!!????   \n",
            "11318         Freezes up consistently!!!   \n",
            "11319               GREAT GAME! But.....   \n",
            "11320         Would Rather Burn A Dollar   \n",
            "\n",
            "                                                  review  \\\n",
            "0      This new version of Things has an entirely dif...   \n",
            "1      I have been using this app for over 3 years no...   \n",
            "2      A lot of people use word because its very stan...   \n",
            "3      I was originally skeptical on paying $7 on a t...   \n",
            "4      This used to be my go to app for note taking. ...   \n",
            "...                                                  ...   \n",
            "11316  I used to play Among Us but not really anymore...   \n",
            "11317  I have been playing this game since the releas...   \n",
            "11318  NEW PROBLEM: the game consistently mis moves t...   \n",
            "11319  So this is a great game! and if your not playi...   \n",
            "11320  As the title states- I wish I had set a dollar...   \n",
            "\n",
            "                                                sentence  rating  is_opinion  \\\n",
            "0      This new version of Things has an entirely dif...       3        True   \n",
            "1      All those contractors were blown away by how e...       5       False   \n",
            "2      I tell them what happens, and they say “so is ...       1        True   \n",
            "3      The ease of use, simplicity, and great functio...       5        True   \n",
            "4      I’m disappointed that even after a year they h...       1        True   \n",
            "...                                                  ...     ...         ...   \n",
            "11316                            Third is the community.       3       False   \n",
            "11317                    I want this Salma girl SO MUCH.       2       False   \n",
            "11318  Ticks you off especially after spending an hou...       2       False   \n",
            "11319  If your wondering the community is ok but cert...       5       False   \n",
            "11320                               Would not recommend.       1       False   \n",
            "\n",
            "            category           term  from     to sentiment  \n",
            "0          usability    new version   6.0   17.0  positive  \n",
            "1                NaN            NaN   NaN    NaN       NaN  \n",
            "2            general            NaN   NaN    NaN  negative  \n",
            "3      effectiveness  functionality  40.0   53.0  positive  \n",
            "4               cost          money  95.0  100.0  negative  \n",
            "...              ...            ...   ...    ...       ...  \n",
            "11316            NaN            NaN   NaN    NaN       NaN  \n",
            "11317            NaN            NaN   NaN    NaN       NaN  \n",
            "11318            NaN            NaN   NaN    NaN       NaN  \n",
            "11319            NaN            NaN   NaN    NaN       NaN  \n",
            "11320            NaN            NaN   NaN    NaN       NaN  \n",
            "\n",
            "[11321 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['app','review_id','sentence_id','title','sentence', 'rating','is_opinion','category','term','from','to'])\n",
        "# df_cleaned = df.dropna()\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btPF95u9l0Md",
        "outputId": "a627efa4-5a69-488b-c8e7-58adcaddfa9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain                                             review  \\\n",
            "0      productivity  This new version of Things has an entirely dif...   \n",
            "1      productivity  I have been using this app for over 3 years no...   \n",
            "2      productivity  A lot of people use word because its very stan...   \n",
            "3      productivity  I was originally skeptical on paying $7 on a t...   \n",
            "4      productivity  This used to be my go to app for note taking. ...   \n",
            "...             ...                                                ...   \n",
            "11316         games  I used to play Among Us but not really anymore...   \n",
            "11317         games  I have been playing this game since the releas...   \n",
            "11318         games  NEW PROBLEM: the game consistently mis moves t...   \n",
            "11319         games  So this is a great game! and if your not playi...   \n",
            "11320         games  As the title states- I wish I had set a dollar...   \n",
            "\n",
            "      sentiment  \n",
            "0      positive  \n",
            "1           NaN  \n",
            "2      negative  \n",
            "3      positive  \n",
            "4      negative  \n",
            "...         ...  \n",
            "11316       NaN  \n",
            "11317       NaN  \n",
            "11318       NaN  \n",
            "11319       NaN  \n",
            "11320       NaN  \n",
            "\n",
            "[11321 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "lhFlsy52l4Fz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkSXnoQel8kz",
        "outputId": "8572b73b-c941-4057-d7d3-578b83d31ac2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.dropna()\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3wosS9pl-od",
        "outputId": "d8f10df0-616f-4547-cd2e-b1227c38fa7d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain                                             review  \\\n",
            "0      productivity  This new version of Things has an entirely dif...   \n",
            "2      productivity  A lot of people use word because its very stan...   \n",
            "3      productivity  I was originally skeptical on paying $7 on a t...   \n",
            "4      productivity  This used to be my go to app for note taking. ...   \n",
            "5      productivity  I use it for years.  It’s tagging capability i...   \n",
            "...             ...                                                ...   \n",
            "10868         games  NEW PROBLEM: the game consistently mis moves t...   \n",
            "10896         games  So amazing game I love it but It gets boring s...   \n",
            "10903         games  Among us is pretty fun but the thing is I get ...   \n",
            "10921         games  This game, is literally filled with memories. ...   \n",
            "10925         games  this game is good in regards to characters and...   \n",
            "\n",
            "      sentiment  \n",
            "0      positive  \n",
            "2      negative  \n",
            "3      positive  \n",
            "4      negative  \n",
            "5      positive  \n",
            "...         ...  \n",
            "10868  positive  \n",
            "10896  negative  \n",
            "10903  positive  \n",
            "10921  positive  \n",
            "10925  negative  \n",
            "\n",
            "[5218 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WZcLEuemBWl",
        "outputId": "fc6c146f-d442-49f1-ad14-896beb6ef7d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "domain       0\n",
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].replace({'positive': 1,'negative': 0})\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMaYjTq-mEb8",
        "outputId": "43e19c69-176b-4ee9-f543-8737735f2c84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain                                             review  \\\n",
            "0      productivity  This new version of Things has an entirely dif...   \n",
            "2      productivity  A lot of people use word because its very stan...   \n",
            "3      productivity  I was originally skeptical on paying $7 on a t...   \n",
            "4      productivity  This used to be my go to app for note taking. ...   \n",
            "5      productivity  I use it for years.  It’s tagging capability i...   \n",
            "...             ...                                                ...   \n",
            "10868         games  NEW PROBLEM: the game consistently mis moves t...   \n",
            "10896         games  So amazing game I love it but It gets boring s...   \n",
            "10903         games  Among us is pretty fun but the thing is I get ...   \n",
            "10921         games  This game, is literally filled with memories. ...   \n",
            "10925         games  this game is good in regards to characters and...   \n",
            "\n",
            "       sentiment  \n",
            "0              1  \n",
            "2              0  \n",
            "3              1  \n",
            "4              0  \n",
            "5              1  \n",
            "...          ...  \n",
            "10868          1  \n",
            "10896          0  \n",
            "10903          1  \n",
            "10921          1  \n",
            "10925          0  \n",
            "\n",
            "[5218 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_tags(raw_text):\n",
        "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "NPXd4yiImI6G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_tags)"
      ],
      "metadata": {
        "id": "XU8om7a-mO7Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(lambda x:x.lower())\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnKlvhhWmRbQ",
        "outputId": "d1a4bf4b-1b66-4e15-cc61-631b3916c071"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain                                             review  \\\n",
            "0      productivity  this new version of things has an entirely dif...   \n",
            "2      productivity  a lot of people use word because its very stan...   \n",
            "3      productivity  i was originally skeptical on paying $7 on a t...   \n",
            "4      productivity  this used to be my go to app for note taking. ...   \n",
            "5      productivity  i use it for years.  it’s tagging capability i...   \n",
            "...             ...                                                ...   \n",
            "10868         games  new problem: the game consistently mis moves t...   \n",
            "10896         games  so amazing game i love it but it gets boring s...   \n",
            "10903         games  among us is pretty fun but the thing is i get ...   \n",
            "10921         games  this game, is literally filled with memories. ...   \n",
            "10925         games  this game is good in regards to characters and...   \n",
            "\n",
            "       sentiment  \n",
            "0              1  \n",
            "2              0  \n",
            "3              1  \n",
            "4              0  \n",
            "5              1  \n",
            "...          ...  \n",
            "10868          1  \n",
            "10896          0  \n",
            "10903          1  \n",
            "10921          1  \n",
            "10925          0  \n",
            "\n",
            "[5218 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "sw_list = stopwords.words('english')\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
      ],
      "metadata": {
        "id": "m4x6EootmUbQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def preprocess(q):\n",
        "\n",
        "    q = str(q).lower().strip()\n",
        "\n",
        "    # Replace certain special characters with their string equivalents\n",
        "    q = q.replace('%', ' percent')\n",
        "    q = q.replace('$', ' dollar ')\n",
        "    q = q.replace('₹', ' rupee ')\n",
        "    q = q.replace('€', ' euro ')\n",
        "    q = q.replace('@', ' at ')\n",
        "\n",
        "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
        "    q = q.replace('[math]', '')\n",
        "\n",
        "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
        "    q = q.replace(',000,000,000 ', 'b ')\n",
        "    q = q.replace(',000,000 ', 'm ')\n",
        "    q = q.replace(',000 ', 'k ')\n",
        "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
        "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
        "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
        "    # Decontracting words\n",
        "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
        "    # https://stackoverflow.com/a/19794953\n",
        "    contractions = {\n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "    }\n",
        "\n",
        "    q_decontracted = []\n",
        "\n",
        "    for word in q.split():\n",
        "        if word in contractions:\n",
        "            word = contractions[word]\n",
        "\n",
        "        q_decontracted.append(word)\n",
        "\n",
        "    q = ' '.join(q_decontracted)\n",
        "    q = q.replace(\"'ve\", \" have\")\n",
        "    q = q.replace(\"n't\", \" not\")\n",
        "    q = q.replace(\"'re\", \" are\")\n",
        "    q = q.replace(\"'ll\", \" will\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    q = BeautifulSoup(q)\n",
        "    q = q.get_text()\n",
        "\n",
        "    # Remove punctuations\n",
        "    pattern = re.compile('\\W')\n",
        "    q = re.sub(pattern, ' ', q).strip()\n",
        "\n",
        "\n",
        "    return q\n"
      ],
      "metadata": {
        "id": "gF0z5hXrmnul"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(preprocess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu9V5uopok2e",
        "outputId": "e6281792-9bc3-4195-8def-d6fa0d828a90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-394ff13b77d1>:163: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  q = BeautifulSoup(q)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['domain'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVBDeFPmoojN",
        "outputId": "b121cdc0-a73e-4322-dd8c-b89f57833f7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "productivity         2378\n",
              "social networking    1974\n",
              "games                 866\n",
              "Name: domain, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "import spacy\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# libraries for visualization\n",
        "!pip install pyLDAvis\n",
        "!pip install pyLDAvis.gensim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a9_5GLcot09",
        "outputId": "91068350-ada7-4f9f-92fd-9c54138bb9b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.24.2 (from pyLDAvis)\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.3)\n",
            "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
            "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.7)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas>=2.0.0->pyLDAvis)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.2.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: funcy, tzdata, numpy, pandas, pyLDAvis\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 numpy-1.26.2 pandas-2.1.3 pyLDAvis-3.4.1 tzdata-2023.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyLDAvis.gensim (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyLDAvis.gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
        "\n",
        "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']):\n",
        "       output = []\n",
        "       for sent in texts:\n",
        "             doc = nlp(sent)\n",
        "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
        "       return output"
      ],
      "metadata": {
        "id": "CPKGsF3JpZeO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list=df['review'].tolist()\n",
        "print(review_list[1])\n",
        "tokenized_reviews = lemmatization(review_list)\n",
        "print(tokenized_reviews[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp5Qqe7SqdXt",
        "outputId": "bda7c6f3-5b2e-4ba8-c38d-c54086a63ed2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lot people use word standard  run problem use it  every update there s problem format  everything page 2  partly page 1  part 3  partly page 2  forth  throughout 200 pages document  try call support reach someone barely speaks english  tell happens  say  so changed something document   yes  closed document yesterday  formatted correctly  updated app today  opened wrong  must middle night i switching apples pages  thanks people work really hard make work  really great effort part  it s fun issue happens macbook ipad  what s point setting something exactly want it  simple update changes everything  it s nonsense\n",
            "['lot', 'people', 'word', 'standard', 'run', 'problem', 'update', 'problem', 'format', 'page', 'page', 'part', 'page', 'page', 'document', 'support', 'tell', 'document', 'document', 'yesterday', 'app', 'today', 'wrong', 'middle', 'night', 'apple', 'page', 'thank', 'people', 'work', 'great', 'effort', 'part', 'fun', 'issue', 'ipad', 'point', 'simple', 'update', 'nonsense']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(tokenized_reviews)\n",
        "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
      ],
      "metadata": {
        "id": "MPbSSXp9rIaA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the object for LDA model using gensim library\n",
        "LDA = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "#LDA model\n",
        "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=3, random_state=100,\n",
        "                chunksize=1000, passes=50,iterations=100)"
      ],
      "metadata": {
        "id": "XAfqJkCRrMbd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model.print_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxA_5vC-sajE",
        "outputId": "b1b1da10-afba-4e74-840a-57748ca4f6f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.054*\"app\" + 0.018*\"note\" + 0.015*\"time\" + 0.013*\"email\" + 0.013*\"thing\" + 0.010*\"feature\" + 0.009*\"word\" + 0.008*\"use\" + 0.008*\"work\" + 0.008*\"version\"'),\n",
              " (1,\n",
              "  '0.044*\"app\" + 0.019*\"phone\" + 0.016*\"message\" + 0.016*\"time\" + 0.015*\"people\" + 0.014*\"call\" + 0.013*\"friend\" + 0.012*\"update\" + 0.010*\"discord\" + 0.010*\"account\"'),\n",
              " (2,\n",
              "  '0.090*\"game\" + 0.018*\"time\" + 0.015*\"fun\" + 0.014*\"thing\" + 0.011*\"people\" + 0.011*\"play\" + 0.011*\"player\" + 0.009*\"good\" + 0.009*\"money\" + 0.009*\"level\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['lda_topics'] = df['review'].apply(lambda x: lda_model[dictionary.doc2bow(x.split())])\n",
        "\n",
        "# Define a function to get the name of the most probable topic\n",
        "def get_most_probable_topic(topic_distribution):\n",
        "    most_probable_topic = max(topic_distribution, key=lambda x: x[1])\n",
        "    topic_id, _ = most_probable_topic\n",
        "    return f\"Topic {topic_id + 1}\"\n",
        "\n",
        "# Create a new column with the names of the most probable topics\n",
        "df['predicted_domain'] = df['lda_topics'].apply(get_most_probable_topic)\n",
        "\n",
        "# Print the DataFrame with the new column\n",
        "print(df[['domain', 'review', 'sentiment', 'predicted_domain']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imyQsaq0tWhI",
        "outputId": "343ef1ce-f742-43ae-a894-b722bfba8a1f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain                                             review  \\\n",
            "0      productivity  new version things entirely different aestheti...   \n",
            "2      productivity  lot people use word standard  run problem use ...   \n",
            "3      productivity  originally skeptical paying dollar 7 todo list...   \n",
            "4      productivity  used go app note taking  year problems writing...   \n",
            "5      productivity  use years  it s tagging capability unique  it ...   \n",
            "...             ...                                                ...   \n",
            "10868         games  new problem  game consistently mis moves piece...   \n",
            "10896         games  amazing game love gets boring trying help thin...   \n",
            "10903         games  among us pretty fun thing get disconnected reg...   \n",
            "10921         games  game  literally filled memories  playing game ...   \n",
            "10925         games  game good regards characters visuals controls ...   \n",
            "\n",
            "       sentiment predicted_domain  \n",
            "0              1          Topic 1  \n",
            "2              0          Topic 1  \n",
            "3              1          Topic 1  \n",
            "4              0          Topic 1  \n",
            "5              1          Topic 1  \n",
            "...          ...              ...  \n",
            "10868          1          Topic 3  \n",
            "10896          0          Topic 3  \n",
            "10903          1          Topic 3  \n",
            "10921          1          Topic 3  \n",
            "10925          0          Topic 3  \n",
            "\n",
            "[5218 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def map_topic_to_domain(topic_name):\n",
        "    if '1' in topic_name:\n",
        "        return 'productivity'\n",
        "    elif '2' in topic_name:\n",
        "        return 'social networking'\n",
        "    elif '3' in topic_name:\n",
        "        return 'games'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# Map predicted topics to domain labels\n",
        "df['predicted_domain'] = df['topic_names'].apply(map_topic_to_domain)\n",
        "print(df)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(df['domain'], df['predicted_domain'])\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Tfx72luRWu",
        "outputId": "73ac5b23-627c-4368-c35c-e86e26b7a138"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             domain                                             review  \\\n",
            "0      productivity  new version things entirely different aestheti...   \n",
            "2      productivity  lot people use word standard  run problem use ...   \n",
            "3      productivity  originally skeptical paying dollar 7 todo list...   \n",
            "4      productivity  used go app note taking  year problems writing...   \n",
            "5      productivity  use years  it s tagging capability unique  it ...   \n",
            "...             ...                                                ...   \n",
            "10868         games  new problem  game consistently mis moves piece...   \n",
            "10896         games  amazing game love gets boring trying help thin...   \n",
            "10903         games  among us pretty fun thing get disconnected reg...   \n",
            "10921         games  game  literally filled memories  playing game ...   \n",
            "10925         games  game good regards characters visuals controls ...   \n",
            "\n",
            "       sentiment                                         lda_topics  \\\n",
            "0              1  [(0, 0.9473305), (1, 0.026310703), (2, 0.02635...   \n",
            "2              0   [(0, 0.460407), (1, 0.3815259), (2, 0.15806715)]   \n",
            "3              1  [(0, 0.81640756), (1, 0.13875394), (2, 0.04483...   \n",
            "4              0                  [(0, 0.8625465), (1, 0.13140202)]   \n",
            "5              1  [(0, 0.9660164), (1, 0.018064508), (2, 0.01591...   \n",
            "...          ...                                                ...   \n",
            "10868          1                  [(1, 0.16337062), (2, 0.8313871)]   \n",
            "10896          0  [(0, 0.040253066), (1, 0.12981963), (2, 0.8299...   \n",
            "10903          1                  [(1, 0.3478829), (2, 0.64824563)]   \n",
            "10921          1                   [(0, 0.3460107), (2, 0.6484869)]   \n",
            "10925          0                  [(1, 0.04118697), (2, 0.9541286)]   \n",
            "\n",
            "      topic_names predicted_domain  \n",
            "0         Topic 1     productivity  \n",
            "2         Topic 1     productivity  \n",
            "3         Topic 1     productivity  \n",
            "4         Topic 1     productivity  \n",
            "5         Topic 1     productivity  \n",
            "...           ...              ...  \n",
            "10868     Topic 3            games  \n",
            "10896     Topic 3            games  \n",
            "10903     Topic 3            games  \n",
            "10921     Topic 3            games  \n",
            "10925     Topic 3            games  \n",
            "\n",
            "[5218 rows x 6 columns]\n",
            "Accuracy: 90.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Test reviews\n",
        "test_reviews = [\n",
        "    \"I really love using Evernote for my work. It helps me stay organized and productive.\",\n",
        "    \"gaming has fun literally takes me back to childhood memories \",\n",
        "    \"I like to discuss with people on discord  \",\n",
        "    \"among gmail,discord,facebook,whatsapp best is discord\",\n",
        "    \"google apps are so smooth \",\n",
        "    \"This is so much fun\",\n",
        "    \"dog\"\n",
        "]\n",
        "\n",
        "# Tokenize the test reviews\n",
        "def preprocess_text(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "tokenized_test_reviews = [preprocess_text(review) for review in test_reviews]\n",
        "\n",
        "# Convert the test reviews to bag-of-words representation\n",
        "bow_test_reviews = [dictionary.doc2bow(tokens) for tokens in tokenized_test_reviews]\n",
        "\n",
        "# Infer topics for the test reviews\n",
        "topics_test_reviews = [lda_model[bow] for bow in bow_test_reviews]\n",
        "\n",
        "# Define a function to get the name of the most probable topic\n",
        "def get_most_probable_topic(topic_distribution):\n",
        "    most_probable_topic = max(topic_distribution, key=lambda x: x[1])\n",
        "    topic_id, _ = most_probable_topic\n",
        "    return f\"Topic {topic_id + 1}\"\n",
        "\n",
        "# Get the names of the most probable topics for the test reviews\n",
        "predicted_topics = [get_most_probable_topic(topics) for topics in topics_test_reviews]\n",
        "\n",
        "# Print the predicted topics for the test reviews\n",
        "# Print the predicted topics and associated keywords for the test reviews\n",
        "#for i, (predicted_topic, topics) in enumerate(zip(predicted_topics, topics_test_reviews), start=1):\n",
        "#   print(f\"Predicted Topic for the test review {i}: {predicted_topic}\")\n",
        "#   print(\"Keywords:\", [word for word, _ in lda_model.show_topic(topics[0][0])])  # Assuming lda_model is your trained LDA model\n",
        "#   print()\n",
        "\n",
        "\n",
        "def map_topic_to_domain(predicted_topic):\n",
        "    if '1' in predicted_topic:\n",
        "        return 'productivity'\n",
        "    elif '2' in predicted_topic:\n",
        "        return 'social networking'\n",
        "    elif '3' in predicted_topic:\n",
        "        return 'games'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# Print the predicted topics and associated keywords for the test reviews\n",
        "for i, (predicted_topic, topics) in enumerate(zip(predicted_topics, topics_test_reviews), start=1):\n",
        "    domain_label = map_topic_to_domain(predicted_topic)\n",
        "    print(f\"Predicted Domain for the test review {i}: {domain_label} or {predicted_topic}\")\n",
        "   # print(f\"Predicted Topic for the test review {i}: {predicted_topic}\")\n",
        "    #print(\"Keywords:\", [word for word, _ in lda_model.show_topic(topics[0][0])])  # Assuming lda_model is your trained LDA model\n",
        "    print()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNa7kVrDyVsC",
        "outputId": "da53946b-1782-4429-db30-452a75437c68"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Domain for the test review 1: productivity or Topic 1\n",
            "\n",
            "Predicted Domain for the test review 2: games or Topic 3\n",
            "\n",
            "Predicted Domain for the test review 3: social networking or Topic 2\n",
            "\n",
            "Predicted Domain for the test review 4: social networking or Topic 2\n",
            "\n",
            "Predicted Domain for the test review 5: productivity or Topic 1\n",
            "\n",
            "Predicted Domain for the test review 6: games or Topic 3\n",
            "\n",
            "Predicted Domain for the test review 7: games or Topic 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['domain'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnWxMq3S0ynP",
        "outputId": "3c2bc7f1-69ad-42ac-938c-43418dfe88c1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "productivity         2378\n",
              "social networking    1974\n",
              "games                 866\n",
              "Name: domain, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['predicted_domain'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tz7UcbV0zGJ",
        "outputId": "1367de2d-07be-4424-f990-149a8c0d9121"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Topic 1    2468\n",
              "Topic 2    1922\n",
              "Topic 3     828\n",
              "Name: predicted_domain, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Function to map topic names to domain labels\n",
        "def map_topic_to_domain(topic_name):\n",
        "    if '1' in topic_name:\n",
        "        return 'productivity'\n",
        "    elif '2' in topic_name:\n",
        "        return 'social networking'\n",
        "    elif '3' in topic_name:\n",
        "        return 'games'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "\n",
        "df['predicted_domain'] = df['topic_names'].apply(map_topic_to_domain)\n",
        "\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy = accuracy_score(df['domain'], df['predicted_domain'])\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gBOHKR61CZM",
        "outputId": "0a0b4309-da4a-4e5f-d85a-4143a5358fc3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.36%\n"
          ]
        }
      ]
    }
  ]
}